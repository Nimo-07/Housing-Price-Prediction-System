{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# California Housing Price Prediction\n",
        "\n",
        "This notebook is a great tool to predict house price based on the California Housing Prices Dataset."
      ],
      "metadata": {
        "id": "CyKq38u7qGag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Setup"
      ],
      "metadata": {
        "id": "9cqR3ySIrJPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cHW7royBpJYw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor, StackingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.inspection import permutation_importance\n",
        "from scipy import stats\n",
        "from scipy.stats import jarque_bera, normaltest, shapiro\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Initial Exploration"
      ],
      "metadata": {
        "id": "eF2y4oy5rRVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing = fetch_california_housing()\n",
        "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df['target'] = housing.target\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
        "print(f\"Target variable statistics:\")\n",
        "print(df['target'].describe())\n",
        "\n",
        "df['rooms_per_household'] = df['AveRooms'] / df['HouseAge']\n",
        "df['bedrooms_per_room'] = df['AveBedrms'] / df['AveRooms']\n",
        "df['population_per_household'] = df['Population'] / df['HouseAge']\n",
        "df['income_per_person'] = df['MedInc'] / (df['Population'] / df['HouseAge'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MROtaeQrRg3",
        "outputId": "ebe84a08-dae1-4564-a0ae-cd5b547a0976"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (20640, 9)\n",
            "Missing values: 0\n",
            "Target variable statistics:\n",
            "count    20640.000000\n",
            "mean         2.068558\n",
            "std          1.153956\n",
            "min          0.149990\n",
            "25%          1.196000\n",
            "50%          1.797000\n",
            "75%          2.647250\n",
            "max          5.000010\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comprehensive Statistical Analysis"
      ],
      "metadata": {
        "id": "G7uXZZg6tx04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jb_stat, jb_pvalue = jarque_bera(df['target'])\n",
        "sw_stat, sw_pvalue = shapiro(df['target'][:5000])\n",
        "ks_stat, ks_pvalue = normaltest(df['target'])\n",
        "\n",
        "print(f\"Jarque-Bera test: statistic={jb_stat:.4f}, p-value={jb_pvalue:.4f}\")\n",
        "print(f\"Shapiro-Wilk test: statistic={sw_stat:.4f}, p-value={sw_pvalue:.4f}\")\n",
        "print(f\"D'Agostino test: statistic={ks_stat:.4f}, p-value={ks_pvalue:.4f}\")\n",
        "\n",
        "correlation_matrix = df.corr()\n",
        "n = len(df)\n",
        "\n",
        "t_stats_target = correlation_matrix['target'] * np.sqrt((n-2) / (1 - correlation_matrix['target']**2))\n",
        "p_values_target = 2 * (1 - stats.t.cdf(np.abs(t_stats_target), n-2))\n",
        "\n",
        "print(\"\\nHighly correlated features with target (p < 0.001):\")\n",
        "target_corr = correlation_matrix['target'].abs().sort_values(ascending=False)\n",
        "significant_corr = p_values_target < 0.001\n",
        "for feature in target_corr[significant_corr].index[1:]:\n",
        "    print(f\"{feature}: {correlation_matrix.loc[feature, 'target']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiPTH7Letx-o",
        "outputId": "7819c3d9-1f65-48c1-fdb1-2e8f94028393"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jarque-Bera test: statistic=3380.4748, p-value=0.0000\n",
            "Shapiro-Wilk test: statistic=0.8941, p-value=0.0000\n",
            "D'Agostino test: statistic=2430.9311, p-value=0.0000\n",
            "\n",
            "Highly correlated features with target (p < 0.001):\n",
            "MedInc: 0.6881\n",
            "bedrooms_per_room: -0.2556\n",
            "AveRooms: 0.1519\n",
            "Latitude: -0.1442\n",
            "income_per_person: 0.1067\n",
            "HouseAge: 0.1056\n",
            "AveBedrms: -0.0467\n",
            "Longitude: -0.0460\n",
            "rooms_per_household: 0.0301\n",
            "Population: -0.0246\n",
            "population_per_household: -0.0149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Feature Engineering"
      ],
      "metadata": {
        "id": "1gj8JGmmuLVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['income_category'] = pd.cut(df['MedInc'], bins=5, labels=['Low', 'Medium-Low', 'Medium', 'Medium-High', 'High'])\n",
        "df['age_category'] = pd.cut(df['HouseAge'], bins=3, labels=['New', 'Medium', 'Old'])\n",
        "df['population_density'] = df['Population'] / (df['AveRooms'] * df['HouseAge'])\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=['income_category', 'age_category'], prefix=['income', 'age'])\n",
        "\n",
        "df_encoded['lat_lon_interaction'] = df_encoded['Latitude'] * df_encoded['Longitude']\n",
        "df_encoded['income_rooms_interaction'] = df_encoded['MedInc'] * df_encoded['AveRooms']\n",
        "df_encoded['age_income_interaction'] = df_encoded['HouseAge'] * df_encoded['MedInc']\n",
        "\n",
        "skewed_features = ['Population', 'AveOccup']\n",
        "for feature in skewed_features:\n",
        "    df_encoded[f'{feature}_log'] = np.log1p(df_encoded[feature])\n",
        "\n",
        "poly_features = ['MedInc', 'AveRooms', 'HouseAge']\n",
        "for feature in poly_features:\n",
        "    df_encoded[f'{feature}_squared'] = df_encoded[feature] ** 2\n",
        "    df_encoded[f'{feature}_cubed'] = df_encoded[feature] ** 3\n",
        "\n",
        "print(f\"Feature engineering completed. New shape: {df_encoded.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7U41iKtuLd6",
        "outputId": "4982716a-4b4b-424b-c317-45c0a430a429"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering completed. New shape: (20640, 33)\n"
          ]
        }
      ]
    }
  ]
}